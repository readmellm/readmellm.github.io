<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ReadMe LLM</title>
    <link rel="stylesheet" href="assets/css/normalize.css">
    <link rel="stylesheet" href="assets/css/style.css">
    <link rel="stylesheet" href="assets/css/workflow.css">
    <link rel="icon" type="image/x-icon" href="assets/images/favicon.ico">
</head>

<body>
    <header class="hero">
        <h1>ReadMe LLM</h1>
        <p>A Framework to Contextualize Software Libraries for LLMs</p>
    </header>

    <nav class="navbar">
        <div class="nav-container">
            <!-- <a href="index.html" class="nav-logo">ReadMe LLM</a> -->
            <ul class="nav-menu">
                <li><a href="#solution">ReadMe.LLM</a></li>
                <li><a
                        href="https://arxiv.org/abs/2504.09798">Pre-print</a>
                </li>
                <li><a href="#demo-video">Demo Video</a></li>
                <li><a href="#workflow">Try it Out!</a></li>
                <li><a href="#social-showcase">Community Voices</a></li>
                <li><a href="#team">Team</a></li>
                <!--                 <li><a href="#library">Library Maker</a></li>
                <li><a href="#developer">Developer</a></li> -->
                <li><a href="#contact">Contact</a></li>
                <!-- <li><a href="">Discussion</a></li> -->
            </ul>
        </div>
    </nav>

    <main>
        <section id="problem">
            <h2>TL;DR</h2>
            <div class="tldr">
                <div class="problem-statement">
                    <p>
                        <b>Problem: </b> Nowadays, LLMs are becoming more and more widely used to write code. 
                        However, coding LLMs struggle with newer or lesser-known libraries due to limited
                        online documentation and/or lack of representation in their training data.
                    </p>
                    <p>
                        <b>Solution:</b> We need LLM oriented documentation. ReadMe.LLM is a solution that addresses
                        this issue by providing structured descriptions
                        of the codebase and other metadata. Library developers provide ReadMe.LLM and engineers can 
                        use them by simply copy pasting its contents into their chat window along with their query.
                    </p>
                </div>
                <div class="compare-graph">
                    <img src="assets/images/compare.png" alt="ReadMe LLM framework">
                </div>
            </div>
        </section>

        <section>
            <h2>Bridging the LLM Knowledge Gap</h2>
            <h3>The Challenge</h3>
            <p>In the foreseen future, developers will use LLMs to generate most of the code, and even the developer itself will be an agent.
                To achieve better efficiency and reusability, libraries are always vital for high quality code. However, not every library
                is as popular as Pandas which has plenty of public documentation, Stack Overflow questions, and other resources that can be easily captured by LLMs.
                Newer or smaller libraries that target a niche domain often lack online documentation, making it
                difficult for LLMs to generate accurate code.</p>
            <!-- New Case Studies Section -->
            <div class="case-studies">
                <h3>Real-World Examples: When LLMs Fail</h3>

                <p>This is not just a theoretical concern. We have conducted experiments without any context across
                    multiple LLMs. The LLMs and libraries we tested, as well as the experiments progress, is introduced as below.</p>

                <table class="llm-table">
                    <thead>
                        <tr>
                            <th>LLM</th>
                            <th>Training Cutoff Date</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><a href="https://openai.com/index/hello-gpt-4o/" target="_blank"
                                    rel="noopener noreferrer">GPT-4o</a></td>
                            <td>October 2023</td>
                        </tr>
                        <tr>
                            <td><a href="https://sonar.perplexity.ai" target="_blank" rel="noopener noreferrer">Sonar
                                    (Llama3 70B)</a></td>
                            <td>December 2023</td>
                        </tr>
                        <tr>
                            <td><a href="https://www.anthropic.com/claude/sonnet" target="_blank"
                                    rel="noopener noreferrer">Claude 3.7 Sonnet</a></td>
                            <td>October 2024</td>
                        </tr>
                        <tr>
                            <td><a href="https://x.ai/news/grok-2" target="_blank" rel="noopener noreferrer">Grok-2</a>
                            </td>
                            <td>July 2024</td>
                        </tr>
                        <tr>
                            <td><a href="https://api-docs.deepseek.com/news/news250120" target="_blank"
                                    rel="noopener noreferrer">DeepSeek R1</a></td>
                            <td>July 2024</td>
                        </tr>
                    </tbody>
                </table>

                We conducted experiments on two distinct libraries:
                <ul>
                    <li>
                        <a href="https://supervision.roboflow.com/latest/" target="_blank" rel="noopener noreferrer">
                            Supervision
                        </a>: A modern, industry-run library created in 2022 with 26.4k stars on Github. This library is
                        a computer vision library that is widely used, but is also very recently developed, possibly
                        causing it to be not included in a LLM's training data.
                    </li>
                    
                    <li>
                        <a href="https://github.com/MITHaystack/digital_rf" target="_blank" rel="noopener noreferrer">
                            DigitalRF
                        </a>: An academic software library created in 2017 with 106 stars on GitHub. This library has
                        limited documentation and tests LLMs ability to handle libraries they are unlikely to have seen
                        during training.
                    </li>

                </ul>
                </p>

                <!-- Case Study 1 -->
                <div class="case-study">
                    <h4>Case Study 1: Supervision</h4>
                    <div class="case-details">
                        <div class="case-description">
                            <p><strong>Task:</strong> For Supervision, we tasked LLMs with detecting and annotating cars in an image. 
                                We selected an image with multiple objects (such as people, or buildings) to introduce complexity and 
                                the LLM-generated code had to identify all cars, add a confidence score annotation, 
                                save the bounding box coordinates, and crop each detected car. </p>
                        </div>
                        <div class="case-outcome">
                            <p><strong>Key Results:</strong> When attempting this task with no additional context, we
                                observed that most of the models had mimal success rates ranging from just 0% to 20%.
                                The sole exception was DeepSeek R1 which had an impressive success rate of 80%, 
                                since it has clearly been trained on the Supervision library. </p>
                            <img src="assets/images/Supervision_NoContext.png" alt="ReadMe LLM framework"
                                class="center">

                        </div>
                        <p>NOTE: Web search is only practical if the website is open and publicly usable. This does not apply to internal libraries.</p>

                    </div>
                </div>

                <!-- Case Study 2 -->
                <div class="case-study">
                    <h4>Case Study 2: DigitalRF</h4>
                    <div class="case-details">
                        <div class="case-description">
                            <p><strong>Task:</strong> Format translation is a common issue to tackle with. Therefore, we 
                                designed a task for LLMs to write a WAV file into a DigitalRF specified HDF5 format using 
                                the DigitalRF library. Specifically, we obtained a WAV file (a 10-second long radio signal) 
                                containing I/Q data using the SDR++ application and tasked LLMs with converting it to a standardized HDF5 format.
                            </p>
                        </div>
                        <div class="case-outcome">
                            <p><strong>Key Results:</strong>Without adding additional context through ReadMe.LLM, we
                                observed poor performances across all 5 of the models ranging from just 0% to 40%
                                success rates.</p>
                            <img src="assets/images/DigitalRF_NoContext.png" alt="ReadMe LLM framework" class="center">
                        </div>
                    </div>
                </div>


            </div>
            <!-- End of Case Studies Section -->

            <div class="impact">
                <h3>So LLM's don't give proper generated code, Who's Impacted?</h3>
                <div class="two-column">
                    <div class="column">
                        <h4>Engineers</h4>
                        <ul>
                            <li>Receive incorrect or non-functional code when starting a project or something new</li>
                            <li>Experience frustration and prolonged debugging</li>
                            <li>Increase company resource expenditure</li>
                        </ul>
                    </div>
                    <div class="column">
                        <h4>Library Developers</h4>
                        <ul>
                            <li>Risk losing potential users</li>
                            <li>See developers abandon their tools</li>
                            <li>Compete against alternatives that work seamlessly with LLMs</li>
                        </ul>
                    </div>
                </div>
            </div>

            <div class="ecosystem-impact">
                <h3>Ecosystem Consequences</h3>
                <!-- <p>This dynamic is reshaping the software ecosystem—smaller libraries risk lack-of-use not due to their
                    technical merit but because LLMs fail to represent them accurately. For developers, this means fewer
                    viable options and slower innovation.</p> -->
                <p>
                    LLMs are reshaping the software ecosystem. 
                    What's not appreciated is that this changes the ecosystem for libraries in particular. 
                    Smaller/niche libraries lose potential users not due to their technical merit 
                    but because LLMs fail to represent their capabilities accurately. 
                    For developers, this means fewer viable options and slower innovation. 
                    For AI agents, this means poorer performance. 
                    Our solution is a framework that ensures LLMs can correctly understand and utilize any software library, 
                    leveling the playing field and fostering a more diverse, innovative, and accessible development landscape.
                </p>

                <!-- <p>Many developers use LLMs to generate code with existing software libraries, leveraging these tools to speed up development or simplify onboarding. However, not all libraries are equally represented in LLM training data.  Newer or smaller libraries often lack online documentation, making it difficult for LLMs to generate accurate code. In contrast, well-established libraries like Pandas have extensive resources that help models produce reliable output, while lesser-known libraries are often misused or misrepresented in AI-generated code.
                This gap negatively impacts both engineers and library developers. Engineers receive incorrect or non-functional code, leading to frustration, prolonged debugging, and increased company resource expenditure. Meanwhile, library developers risk losing potential users as developers abandon their tools in favor of alternatives that work seamlessly with LLM-generated code. 
                This dynamic is reshaping the software ecosystem—smaller libraries risk obsolescence not due to their technical merit but because LLMs fail to represent them accurately. For developers, this means fewer viable options and slower innovation. Our solution is a framework that ensures LLMs can correctly understand and utilize any software library, leveling the playing field and fostering a more diverse, innovative, and accessible development landscape.
                </p> -->
        </section>

        <section id="solution">
            <h2>ReadMe.LLM</h2>
            <!-- <img src="assets/images/solution.png" alt="ReadMe LLM framework" class="center"> -->

            <p>We propose ReadMe.LLM, LLM-oriented documentation to streamline library usage by LLMs:</p>
            <ul>
                <li>Optimized Documentation for LLMs: ReadMe.LLM provides structured descriptions of the codebase and
                    other metadata.</li>
                <li>Seamless Integration: Library developers attach ReadMe.LLM to their codebase, allowing LLMs to
                    accurately utilize the library without requiring additional fine-tuning.</li>
                <li>Enhanced Developer Experience: Developers simply copy and paste the ReadMe.LLM contents into the LLM
                    chat window and ask their query. The LLM now having better context about the library can select
                    appropriate functions to correctly implement users' design, even without requiring new IDEs or infrastructure.</li>
            </ul>
            <p>Our approach shifts the focus from fixing LLMs' limitations to empowering libraries to be LLM-friendly,
                fostering adoption of emerging libraries. The respective workflows for a Library Developer and Engineer
                are illustrated below:</p>
            <p><b>Engineer workflow:</b></p>
            <img src="assets/images/workflow2.png" alt="User Chart" class="center">
            <p><b>Library Developer workflow:</b></p>
            <img src="assets/images/workflow1.png" alt="User Chart" class="center">


            <div class="case-studies">
                <h3>ReadMe.LLM's Success</h3>
                <p>We repeated the experiments on DigitalRF and Supervision mentioned in the previous section, and we
                    observed significantly better results using the ReadMe.LLM framework:</p>
                <!-- Case Study 1 -->
                <div class="case-study">
                    <h4>Case Study 1: Supervision</h4>
                    <div class="case-details">
                        <div class="case-description">
                            <!-- <p><strong>Task:</strong> For Supervision, we tasked LLMs with detecting and annotating cars in an image. We selected an image with multiple objects (such as people, or buildings) to introduce complexity and test the LLMs' ability to differentiate between relevant and irrelevant detections. The LLM had to identify all cars, add a confidence score annotation, save the bounding box coordinates, and crop each detected car. </p> -->
                        </div>
                        <div class="case-outcome">
                            <p><strong>Key Results:</strong> We created an optimal ReadME.LLM for Supervision by 
                                first testing until we reached a 100% success rate with Sonar with search enabled. The structure
                                of this final ReadMe.LLM included examples, function signatures, and context descriptions.
                                Then we tested this across all 5 models and as can be seen in the graph below
                                we were able to reach 100% success rate across all 5 models.
                            </p>
                            <img src="assets/images/Success_Supervision.png" alt="ReadMe LLM framework" class="center">
                        </div>
                    </div>
                </div>
                <!-- Case Study 2 -->
                <div class="case-study">
                    <h4>Case Study 2: DigitalRF</h4>
                    <div class="case-details">
                        <div class="case-description">
                            <!-- <p><strong>Task:</strong> For DigitalRF, we tasked the LLMs with writing a WAV file into HDF5 format. We obtained a WAV file (a 10-second long radio signal) containing I/Q data using the SDR++ application and tasked LLMs with converting it to a standardized HDF5 format. </p> -->
                        </div>
                        <div class="case-outcome">
                            <p><strong>Key Results:</strong> We used a similar structure as the final ReadME.LLM for Supervision,
                                and created a text file with examples and function signatures of the major read and write functions in the library.
                                We also included a few context descriptions. In our testing we observed that the final ReadME.LLM with search achieved a 100%
                                succss rate with all the models excpet for GPT-4o which had an 80% success rate. This shows that there is still room to iterate
                            and improve upon the current structure of our ReadME.LLM for DigitalRF.</p>
                            <img src="assets/images/Success_DigitalRF.png" alt="ReadMe LLM framework" class="center">
                        </div>
                    </div>
                </div>
            </div>
            <!-- End of Case Studies Section -->
        </section>

        <section id="demo-video">
            <h2>Demo Video</h2>
            <p>Watch our demonstration of how ReadMe.LLM helps improve code generation for engineers. You can access all
                of the materials used in the video in the below "Try it Out!" section.</p>
            <div class="video-container">
                <video width="800" height="450" controls poster="assets/images/thumbnail.png">
                    <source src="assets/videos/FinalVideo.mp4" type="video/mp4">
                    <source src="assets/videos/FinalVideo.webm" type="video/webm">
                    Your browser does not support the video tag.
                </video>
            </div>
        </section>


        <section id="workflow">
            <h2>Try it Out!</h2>
            <p>Follow the steps in the screen shot below to generate high quality code with the help of ReadMe.LLM! </p>
            <img src="assets/images/github_to_gpt.png" alt="User Chart" class="center large-image">
            <img src="assets/images/gpt_to_code.png" alt="User Chart" class="center large-image">

            <p>Here is an example task using the Supervision Library, feel free to try it <b>with and without
                    ReadMe.LLM</b>! See what happens</p>
            <p><b>Task:</b></p>
            <div class="code-container">
                <button class="copy-button" onclick="copyCode()">Copy</button>
                <div id="codeBlock">
                    <p>Using the Supervision Library, find all the people in the “original_image”
                        and annotate them with a blur. Overlay the detected people in the original
                        image with “oski_image”. Print both the annotated image and the overlayed image.
                    </p>
                    <!-- &lt;div&gt;Hello, World!&lt;/div&gt;
              &lt;p&gt;This is a sample code block.&lt;/p&gt; -->
                </div>
            </div>
            <p><b>ReadMe.LLM:</b></p>
            <div class="code-container">
                <button class="copy-button" onclick="copyCode()">Copy</button>
                <div id="readme-content"></div>
            </div>
            <a href="assets/images/original_image.jpeg" download="original_image.jpeg" class="download-btn">
                <button>Download Original Image</button>
            </a>
            <a href="assets/images/oski_image.png" download="oski_image.png" class="download-btn">
                <button>Download Annotated Image</button>
            </a>
            <p>Here is the expected output is the code is correct</p>
            <img src="assets/images/blur.jpeg" alt="User Chart" class="center">
            <img src="assets/images/oski_people.jpeg" alt="User Chart" class="center">

        </section>


        <section id="social-showcase">
            <h2>Community Voices</h2>
            <div class="social-container">
                <div class="twitter-feed">
                    <div class="twitter-posts-wrapper">
                        <div class="scroll-arrow left-arrow">&#10094;</div>
                        <div class="twitter-posts-container">
                            <div class="twitter-posts">
                                <blockquote class="twitter-tweet">
                                    <p lang="en" dir="ltr">It&#39;s 2025 and most content is still written for humans instead of
                                        LLMs. 99.9% of attention is about to be LLM attention, not human attention.<br><br>E.g.
                                        99% of libraries still have docs that basically render to some pretty .html static pages
                                        assuming a human will click through them.…</p>&mdash; Andrej Karpathy (@karpathy) <a
                                        href="https://twitter.com/karpathy/status/1899876370492383450?ref_src=twsrc%5Etfw">March
                                        12, 2025</a>
                                </blockquote>
                                <blockquote class="twitter-tweet">
                                    <p lang="en" dir="ltr">Good tip from Replit's <a
                                            href="https://twitter.com/mattppal?ref_src=twsrc%5Etfw">@mattppal</a> at AI Dev 25
                                        on debugging while vibe coding: Large part of it is looking at outputs to figure out
                                        what context you have that LLM does not, so that you can give it that context and help
                                        it get unstuck. Sometimes pasting in the error messages is… <a
                                            href="https://t.co/4HSLeoviLp">pic.twitter.com/4HSLeoviLp</a></p>&mdash; Andrew Ng
                                    (@AndrewYNg) <a
                                        href="https://twitter.com/AndrewYNg/status/1900617330906067136?ref_src=twsrc%5Etfw">March
                                        14, 2025</a>
                                </blockquote>
                                <blockquote class="twitter-tweet"><p lang="en" dir="ltr">One of the biggest mindset shifts I've had 
                                    building AI products:<br><br>When working with LLMs, let go of deterministic thinking 
                                    (&quot;X input = Y output&quot;).<br><br>It's not about writing code — it's about shaping behavior 
                                    through context.<br><br>Guide, iterate, adapt.<br><br>Directions, not destinations.…</p>&mdash; 
                                    Guille / Building Zapia AI (@guillepenaa) 
                                    <a href="https://twitter.com/guillepenaa/status/1910414013088874994?ref_src=twsrc%5Etfw">April 10, 2025</a>
                                </blockquote>
                            </div>
                        </div>
                        <div class="scroll-arrow right-arrow">&#10095;</div>
                    </div>
                    <div class="scroll-dots"></div>
                </div>
            </div>
            <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
            <script>
                document.addEventListener('DOMContentLoaded', function() {
                    // Wait for Twitter widgets to load
                    if (typeof twttr !== 'undefined') {
                        twttr.ready(function() {
                            twttr.events.bind('rendered', initializeScrolling);
                        });
                    } else {
                        // Fallback if Twitter widgets don't load properly
                        window.addEventListener('load', function() {
                            setTimeout(initializeScrolling, 1000);
                        });
                    }
                    
                    function initializeScrolling() {
                        const container = document.querySelector('.twitter-posts-container');
                        const tweetsWrapper = document.querySelector('.twitter-posts');
                        const tweets = document.querySelectorAll('.twitter-tweet');
                        const leftArrow = document.querySelector('.left-arrow');
                        const rightArrow = document.querySelector('.right-arrow');
                        const dotsContainer = document.querySelector('.scroll-dots');
                        
                        // Clear any existing dots
                        dotsContainer.innerHTML = '';
                        
                        // Create navigation dots
                        tweets.forEach((_, index) => {
                            const dot = document.createElement('div');
                            dot.className = 'dot';
                            if (index === 0) dot.classList.add('active');
                            dot.addEventListener('click', () => scrollToTweet(index));
                            dotsContainer.appendChild(dot);
                        });
                        
                        const dots = document.querySelectorAll('.dot');
                        let currentIndex = 0;
                        
                        // Scroll to specific tweet by index
                        function scrollToTweet(index) {
                            if (tweets[index]) {
                                currentIndex = index;
                                const tweetOffset = tweets[index].offsetLeft - tweetsWrapper.offsetLeft;
                                container.scrollTo({
                                    left: tweetOffset,
                                    behavior: 'smooth'
                                });
                                updateActiveDot();
                            }
                        }
                        
                        // Update active dot based on current index
                        function updateActiveDot() {
                            dots.forEach((dot, i) => {
                                dot.classList.toggle('active', i === currentIndex);
                            });
                        }
                        
                        // Arrow navigation - fixed to properly handle the third tweet
                        leftArrow.addEventListener('click', () => {
                            if (currentIndex > 0) {
                                scrollToTweet(currentIndex - 1);
                            }
                        });
                        
                        rightArrow.addEventListener('click', () => {
                            if (currentIndex < tweets.length - 1) {
                                scrollToTweet(currentIndex + 1);
                            }
                        });
                        
                        // Update active dot on scroll
                        container.addEventListener('scroll', () => {
                            const scrollPosition = container.scrollLeft;
                            
                            // Find which tweet is most visible
                            let closestTweet = 0;
                            let minDistance = Infinity;
                            
                            tweets.forEach((tweet, index) => {
                                const tweetOffset = tweet.offsetLeft - tweetsWrapper.offsetLeft;
                                const distance = Math.abs(scrollPosition - tweetOffset);
                                
                                if (distance < minDistance) {
                                    minDistance = distance;
                                    closestTweet = index;
                                }
                            });
                            
                            if (currentIndex !== closestTweet) {
                                currentIndex = closestTweet;
                                updateActiveDot();
                            }
                        });
                        
                        // Hide arrows if no overflow
                        function checkOverflow() {
                            const isOverflowing = container.scrollWidth > container.clientWidth;
                            leftArrow.style.display = isOverflowing ? 'flex' : 'none';
                            rightArrow.style.display = isOverflowing ? 'flex' : 'none';
                            dotsContainer.style.display = isOverflowing && tweets.length > 1 ? 'flex' : 'none';
                        }
                        
                        // Check overflow initially and on window resize
                        checkOverflow();
                        window.addEventListener('resize', checkOverflow);
                        
                        // Add keyboard navigation
                        document.addEventListener('keydown', function(e) {
                            if (e.key === 'ArrowLeft') {
                                if (currentIndex > 0) {
                                    scrollToTweet(currentIndex - 1);
                                }
                            } else if (e.key === 'ArrowRight') {
                                if (currentIndex < tweets.length - 1) {
                                    scrollToTweet(currentIndex + 1);
                                }
                            }
                        });
                        
                        // Add touch swipe support
                        let touchStartX = 0;
                        let touchEndX = 0;
                        
                        container.addEventListener('touchstart', e => {
                            touchStartX = e.changedTouches[0].screenX;
                        });
                        
                        container.addEventListener('touchend', e => {
                            touchEndX = e.changedTouches[0].screenX;
                            handleSwipe();
                        });
                        
                        function handleSwipe() {
                            const swipeThreshold = 50;
                            if (touchStartX - touchEndX > swipeThreshold) {
                                // Swipe left - go to next tweet
                                if (currentIndex < tweets.length - 1) {
                                    scrollToTweet(currentIndex + 1);
                                }
                            } else if (touchEndX - touchStartX > swipeThreshold) {
                                // Swipe right - go to previous tweet
                                if (currentIndex > 0) {
                                    scrollToTweet(currentIndex - 1);
                                }
                            }
                        }
                    }
                });
            </script>
            <style>
                /* Twitter Feed Container */
                .twitter-feed {
                    background-color: #f8f9fa;
                    border-radius: 12px;
                    padding: 1.5rem;
                    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.05);
                    max-width: 90%;
                    margin: 0 auto;
                    position: relative;
                }
        
                .twitter-feed h3 {
                    margin-top: 0;
                    margin-bottom: 1.5rem;
                    color: #1da1f2;
                    font-size: 1.5rem;
                    text-align: center;
                }
        
                /* Horizontal Scrolling Container */
                .twitter-posts-wrapper {
                    position: relative;
                    display: flex;
                    align-items: center;
                    width: 100%;
                }
        
                .twitter-posts-container {
                    width: 100%;
                    overflow-x: auto;
                    overflow-y: hidden;
                    white-space: nowrap;
                    scroll-behavior: smooth;
                    scrollbar-width: none; /* Firefox */
                    -ms-overflow-style: none; /* IE and Edge */
                    scroll-snap-type: x mandatory;
                    padding: 1rem 0;
                }
        
                /* Hide scrollbar for Chrome, Safari and Opera */
                .twitter-posts-container::-webkit-scrollbar {
                    display: none;
                }
        
                .twitter-posts {
                    display: inline-flex;
                    gap: 1.5rem;
                    padding: 0 0.5rem;
                }
        
                /* Tweet Card Styling */
                .twitter-posts .twitter-tweet {
                    scroll-snap-align: center;
                    display: inline-block;
                    width: 500px !important; /* Fixed width for each tweet */
                    max-width: 500px !important;
                    min-width: 300px !important;
                    margin: 0 !important;
                    white-space: normal;
                    vertical-align: top;
                    border-radius: 12px;
                    overflow: hidden;
                    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
                    transition: transform 0.3s ease;
                }
        
                .twitter-posts .twitter-tweet:hover {
                    transform: translateY(-5px);
                }
        
                /* Navigation Arrows */
                .scroll-arrow {
                    position: absolute;
                    top: 50%;
                    transform: translateY(-50%);
                    width: 40px;
                    height: 40px;
                    background-color: rgba(29, 161, 242, 0.8);
                    color: white;
                    border-radius: 50%;
                    display: flex;
                    align-items: center;
                    justify-content: center;
                    font-size: 1.2rem;
                    cursor: pointer;
                    z-index: 10;
                    transition: background-color 0.2s, transform 0.2s;
                    user-select: none;
                }
        
                .scroll-arrow:hover {
                    background-color: rgba(29, 161, 242, 1);
                    transform: translateY(-50%) scale(1.1);
                }
        
                .left-arrow {
                    left: -20px;
                }
        
                .right-arrow {
                    right: -20px;
                }
        
                /* Scroll Dots */
                .scroll-dots {
                    display: flex;
                    justify-content: center;
                    gap: 8px;
                    margin-top: 1rem;
                }
        
                .dot {
                    width: 10px;
                    height: 10px;
                    border-radius: 50%;
                    background-color: #ccc;
                    cursor: pointer;
                    transition: background-color 0.2s;
                }
        
                .dot.active {
                    background-color: #1da1f2;
                }
        
                /* Responsive adjustments */
                @media (max-width: 768px) {
                    .twitter-posts .twitter-tweet {
                        width: 90vw !important;
                        min-width: 280px !important;
                    }
                    
                    .scroll-arrow {
                        width: 30px;
                        height: 30px;
                        font-size: 1rem;
                    }
                }
            </style>
        </section>
        
        
        



        <!-- Team Section -->
        <section id="team">
            <h2>Meet Our Team</h2>

            <div class="team-container">
                <!-- Team Member 1 -->
                <div class="team-member">
                    <img src="assets/images/gomez.jpg" alt="Team Member 1" class="team-member-image">
                    <div class="member-info">
                        <h3>Alejandro Gómez Soteres</h3>
                        <!-- <p class="member-bio">Short bio describing this team member's background, expertise, and contributions to the ReadMe LLM project.</p> -->
                        <div class="social-links">
                            <a href="https://www.linkedin.com/in/gs-alejandro/">
                                <img src="assets/images/linkedin-logo.png" alt="LinkedIn" class="social-icon">
                            </a>

                            <!-- <a href="#">GitHub</a> -->
                        </div>
                    </div>
                </div>

                <!-- Team Member 2 -->
                <div class="team-member">
                    <img src="assets/images/sandya1.jpg" alt="Team Member 2" class="team-member-image">
                    <div class="member-info">
                        <h3>Sandya Wijaya</h3>
                        <!-- <p class="member-bio">Short bio describing this team member's background, expertise, and contributions to the ReadMe LLM project.</p> -->
                        <div class="social-links">
                            <a href="https://www.linkedin.com/in/sandyawijaya/">
                                <img src="assets/images/linkedin-logo.png" alt="LinkedIn" class="social-icon">
                            </a>
                            <!-- <a href="#">GitHub</a> -->
                        </div>
                    </div>
                </div>

                <!-- Team Member 3 -->
                <div class="team-member">
                    <img src="assets/images/shri.JPG" alt="Team Member 3" class="team-member-image">
                    <div class="member-info">
                        <h3>Shriyanshu Kode</h3>
                        <!-- <p class="member-bio">Short bio describing this team member's background, expertise, and contributions to the ReadMe LLM project.</p> -->
                        <div class="social-links">
                            <a href="https://www.linkedin.com/in/shriyanshuk/">
                                <img src="assets/images/linkedin-logo.png" alt="LinkedIn" class="social-icon">
                            </a>
                            <!-- <a href="#">GitHub</a> -->
                        </div>
                    </div>
                </div>

                <!-- Team Member 4 -->
                <div class="team-member">
                    <img src="assets/images/jacob_headshot.jpeg" alt="Team Member 4" class="team-member-image">
                    <div class="member-info">
                        <h3>Jacob Bolano</h3>
                        <!-- <p class="member-bio">Short bio describing this team member's background, expertise, and contributions to the ReadMe LLM project.</p> -->
                        <div class="social-links">
                            <a href="https://www.linkedin.com/in/jacobbolano/">
                                <img src="assets/images/linkedin-logo.png" alt="LinkedIn" class="social-icon">
                            </a>
                            <!-- <a href="#">GitHub</a> -->
                        </div>
                    </div>
                </div>

                <!-- Team Member 5 -->
                <div class="team-member">
                    <img src="assets/images/yue.jpeg" alt="Team Member 5" class="team-member-image">
                    <div class="member-info">
                        <h3>Yue Huang</h3>
                        <!-- <p class="member-bio">Short bio describing this team member's background, expertise, and contributions to the ReadMe LLM project.</p> -->
                        <div class="social-links">
                            <a href="https://www.linkedin.com/in/yuehuang01/">
                                <img src="assets/images/linkedin-logo.png" alt="LinkedIn" class="social-icon">
                            </a>
                            <!-- <a href="#">GitHub</a> -->
                        </div>
                    </div>
                </div>

                <!-- Team Member 6 -->
                <div class="team-member">
                    <img src="assets/images/sahai.jpg" alt="Team Member 6" class="team-member-image">
                    <div class="member-info">
                        <h3>Anant Sahai</h3>
                        <div class="member-title">Advisor</div>
                        <!-- <p class="member-bio">Short bio describing this team member's background, expertise, and contributions to the ReadMe LLM project.</p> -->
                        <div class="social-links">
                            <a href="https://www.linkedin.com/in/anantsahai/">
                                <img src="assets/images/linkedin-logo.png" alt="LinkedIn" class="social-icon">
                            </a>
                            <!-- <a href="#">GitHub</a> -->
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!--         <section id="library">
            <h2>Library Makers</h2>
            <p><b>Challenge:</b> Loss of potential users to bigger alternative libraries AI is better at coding with.</p>
            <p><b>Action:</b> Create a ReadMe.LLM.</p>
            <p></p><b>Result:</b> More adoption and thus a fairer playing field.</p>
        </section> -->

        <!--         <section id="developer">
            <h2>Developers</h2>
            <p><b>Challenge:</b> Incorrect code causes frustration and wastes time and resources for debugging.</p>
            <p><b>Action:</b> Prompt LLM with ReadMe.LLM file.</p>
            <p></p><b>Result:</b> Seamless development and thus faster innovation.</p>
        </section> -->

        <section id="citation">
            <h2>Cite</h2>
            <div class="content-box visual" style="margin-top: 2rem; max-width: 100%; padding: 1.5rem; border-radius: 8px; background-color: #f8f9fa; border: 1px solid #e9ecef;">
                <div class="citation-container">
                    <p style="margin-bottom: 1rem; font-size: 1rem; line-height: 1.5;">
                        If you rely on ReadMe.LLM and artifacts, we request that you cite the underlying paper:
                    </p>
                    <pre style="background-color: #f1f3f5; padding: 1rem; border-radius: 6px; overflow-x: auto; font-family: monospace; font-size: 0.9rem; line-height: 1.4; border-left: 4px solid #6c757d;">@misc{wijaya2025readmellmframeworkhelpllms,
            title={ReadMe.LLM: A Framework to Help LLMs Understand Your Library}, 
            author={Sandya Wijaya and Jacob Bolano and Alejandro Gomez Soteres and Shriyanshu Kode and Yue Huang and Anant Sahai},
            year={2025},
            eprint={2504.09798},
            archivePrefix={arXiv},
            primaryClass={cs.SE},
            url={https://arxiv.org/abs/2504.09798}, 
        }</pre>
                    <div style="margin-top: 1rem; text-align: right;">
                        <a href="https://arxiv.org/abs/2504.09798" style="text-decoration: none; color: #0366d6; font-weight: 500;">View on arXiv →</a>
                    </div>
                </div>
            </div>
        </section>
        

        <section id="contact">
            <h2>Contact</h2>
            <p>Please send any questions or inquiries to readmellm.ucb@gmail.com</p>
        </section>

    </main>

    <footer>
        <p></p>
    </footer>

    <script src="assets/js/main.js"></script>
</body>

</html>